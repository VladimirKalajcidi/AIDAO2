{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirkalajcidi/miniconda/envs/aidao2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "from enum import Enum\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import typing as t\n",
    "\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    show_photos, \n",
    "    create_dataloader,\n",
    "    train_epoch,\n",
    "    test_epoch,\n",
    "    plot_history,\n",
    "    print_model_params_required_grad,\n",
    "    PUBLIC_DATA_FOLDER_PATH,\n",
    "    PUBLIC_DATA_DESCRIPTION_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = pd.read_csv(PUBLIC_DATA_DESCRIPTION_PATH, index_col='filename').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarSide(Enum):\n",
    "    FRONT = 0\n",
    "    BACK = 1\n",
    "    LEFT = 2\n",
    "    RIGHT = 3\n",
    "    UNKNOWN = 5\n",
    "    \n",
    "class FraudResolution(Enum):\n",
    "    ALL_GOOD = 0\n",
    "    LACK_OF_PHOTOS = 1\n",
    "    BLURRY_PHOTO = 2\n",
    "    SCREEN_PHOTO = 3\n",
    "    DARK_PHOTO = 4\n",
    "    INCOMPLETE_CAPTURE = 5\n",
    "    RUDE_CONTENT = 6\n",
    "    \n",
    "class DamageResolution(Enum):\n",
    "    NO_DEFECT = 0\n",
    "    DEFECT = 1\n",
    "    BAD_PHOTO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_STD = [0.229, 0.224, 0.225]\n",
    "RESIZE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "def pil_open(image_data: bytes) -> Image:\n",
    "    return Image.open(io.BytesIO(image_data))\n",
    "\n",
    "\n",
    "def preprocess(image_data: t.Optional[bytes]) -> torch.Tensor:\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(pil_open),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(RESIZE_SIZE),\n",
    "        transforms.Normalize(IMAGENET_RGB_MEAN, IMAGENET_RGB_STD),\n",
    "    ])(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_damage_target(damage_resolution, *args):\\n    return int(damage_resolution != DamageResolution.NO_DEFECT.name)\\n\\ndamage_target = description.damage_verdict.apply(lambda x: get_damage_target(x))'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_damage_target(damage_resolution, *args):\n",
    "    return int(damage_resolution != DamageResolution.NO_DEFECT.name)\n",
    "\n",
    "damage_target = description.damage_verdict.apply(lambda x: get_damage_target(x))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fraud_target(fraud_verdict):\n",
    "    return 0 if fraud_verdict == \"ALL_GOOD\" else 1\n",
    "\n",
    "fraud_target = description.apply(lambda row: get_fraud_target(row['fraud_verdict']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_FRACTION = 0.7\n",
    "\n",
    "total_size = fraud_target.shape[0]\n",
    "train_size = int(total_size * TRAIN_FRACTION)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    img_dir_path=PUBLIC_DATA_FOLDER_PATH,\n",
    "    target_map=fraud_target[:train_size].to_dict(),\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader(\n",
    "    img_dir_path=PUBLIC_DATA_FOLDER_PATH,\n",
    "    target_map=fraud_target[train_size:total_size].to_dict(),\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    device, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler=None, \n",
    "    save_best_model=True\n",
    "):\n",
    "    best_test_loss = None\n",
    "    best_state_dict = None\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    test_loss_history = []\n",
    "    test_acc_history = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, \n",
    "            device,\n",
    "            train_loader, \n",
    "            criterion, \n",
    "            optimizer\n",
    "        )\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        test_loss, test_acc = test_epoch(model, device, test_loader, criterion)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_acc_history.append(test_acc)\n",
    "        \n",
    "        if best_test_loss is None or test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(\n",
    "            train_loss_history, \n",
    "            test_loss_history, \n",
    "            train_acc_history, \n",
    "            test_acc_history\n",
    "        )\n",
    "    \n",
    "    if save_best_model:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_loss_history, \n",
    "        'test_loss': test_loss_history,\n",
    "        'train_acc': train_acc_history,\n",
    "        'test_acc': test_acc_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace classifier\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "def BCELoss_class_weighted(weights):\n",
    "    \n",
    "    def loss(pred, target):\n",
    "        pred = torch.clamp(pred, min=1e-7, max=1-1e-7)\n",
    "        bce = -weights[1] * target * torch.log(pred) - (1 - target) * weights[0] * torch.log(1 - pred)\n",
    "        return torch.sum(bce)\n",
    "\n",
    "    return loss\n",
    "\n",
    "criterion = BCELoss_class_weighted(weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_model_params_required_grad(model)\n",
    "\n",
    "resnet_simple_fraud_log = train_model(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    train_loader=train_loader, \n",
    "    test_loader=test_loader, \n",
    "    epochs=3, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'baseline_fraud_resnet18.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: There are only **filename**, **pass_id**, **plan_side** in private data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from utils import get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('baseline_fraud_resnet18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = get_predictions(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1240a46c165f6ca</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1252381f49a5101</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1256f6b65a2193b</th>\n",
       "      <td>1</td>\n",
       "      <td>0.846898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a12659d9dceef2aa</th>\n",
       "      <td>1</td>\n",
       "      <td>0.855848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1289c09d5a573cc</th>\n",
       "      <td>1</td>\n",
       "      <td>0.967882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  real  prediction\n",
       "pass_id                           \n",
       "a1240a46c165f6ca     0    0.000073\n",
       "a1252381f49a5101     1    0.992290\n",
       "a1256f6b65a2193b     1    0.846898\n",
       "a12659d9dceef2aa     1    0.855848\n",
       "a1289c09d5a573cc     1    0.967882"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_complex_target(row):\n",
    "    real = int(\n",
    "        #row.plan_side != row.fact_side or \n",
    "        row.fraud_verdict == 'ALL_GOOD'\n",
    "        #row.damage_verdict != 'NO_DEFECT'\n",
    "    )\n",
    "    return pd.Series(\n",
    "        data=[row.pass_id, real, row.prediction],\n",
    "        index=['pass_id', 'real', 'prediction'],\n",
    "    )\n",
    "\n",
    "# All predictions for each vehicle are aggregated into a single value, \n",
    "# and the metric is calculated based on the inspections.\n",
    "test_verdicts = test_predictions.merge(\n",
    "    description,\n",
    "    on=['pass_id', 'plan_side']\n",
    ").apply(make_complex_target, axis=1).groupby('pass_id').max()\n",
    "\n",
    "test_verdicts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple fraud target roc_auc_score: 0.9701099439910326\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(test_verdicts.real, test_verdicts.prediction)\n",
    "print(f'simple fraud target roc_auc_score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_script = '''\n",
    "import typing as t\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import (\n",
    "    get_predictions, \n",
    "    create_dataloader,\n",
    "    PRIVATE_DATA_FOLDER_PATH, \n",
    "    PRIVATE_DATA_DESCRIPTION_PATH,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_STD = [0.229, 0.224, 0.225]\n",
    "RESIZE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "def pil_open(image_data: bytes) -> Image:\n",
    "    return Image.open(io.BytesIO(image_data))\n",
    "\n",
    "\n",
    "def preprocess(image_data: t.Optional[bytes]) -> torch.Tensor:\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(pil_open),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(RESIZE_SIZE),\n",
    "        transforms.Normalize(IMAGENET_RGB_MEAN, IMAGENET_RGB_STD),\n",
    "    ])(image_data)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = torch.load('baseline_fraud_resnet18.pt', map_location=device)\n",
    "\n",
    "description = pd.read_csv(PRIVATE_DATA_DESCRIPTION_PATH, index_col='filename').sort_index()\n",
    "# there is no real target in private data description\n",
    "dummy_target = {key: 0 for key in description.index}\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    img_dir_path=PRIVATE_DATA_FOLDER_PATH,\n",
    "    target_map=dummy_target,\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")\n",
    "\n",
    "solution = get_predictions(model, device, val_loader)\n",
    "solution = solution[['pass_id', 'prediction']].groupby('pass_id').max()\n",
    "solution.to_csv('./predictions.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the .zip to submit\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "def make_zip_submission(model_path, solution_script):\n",
    "\n",
    "    with open('run.py', 'w') as f_run:\n",
    "        f_run.write(solution_script)\n",
    "\n",
    "    with open('run.sh', 'w') as f_run_sh:\n",
    "        f_run_sh.write('python run.py')\n",
    "\n",
    "    with open('prepare.py', 'w') as f_run:\n",
    "        f_run.write('print(\"do nothing\")')\n",
    "\n",
    "    with open('prepare.sh', 'w') as f_run_sh:\n",
    "        f_run_sh.write('python prepare.py')\n",
    "\n",
    "    with open('Makefile', 'w') as f_makefile:\n",
    "        f_makefile.write(\n",
    "'''prepare:\n",
    "\\tbash prepare.sh\n",
    "run:\n",
    "\\tbash run.sh\n",
    "''')\n",
    "\n",
    "    submission_zip = zipfile.ZipFile(\n",
    "        f\"submission-{datetime.datetime.now()}.zip\".replace(':', '-').replace(' ', '-'),\n",
    "        \"w\"\n",
    "    )\n",
    "    submission_zip.write('./Makefile', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('run.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('run.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('prepare.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('prepare.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write(model_path, compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('utils.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "    submission_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_zip_submission(model_path='baseline_fraud_resnet18.pt', solution_script=solution_script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidao2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
